# ğŸš€ Reward Rover

**Reward Rover** ist mein Versuch, Reinforcement Learning greifbar zu machen.  
Nicht in Form von endlosen Formeln oder komplizierten Papers, sondern als interaktives Spiel.  
Ein kleiner Rover lÃ¤uft Ã¼ber ein Grid, stolpert in Mauern, kassiert Strafen oder findet Belohnungen â€“ und lernt dabei mit jeder Episode, bessere Entscheidungen zu treffen.

---

## Warum dieses Projekt?

Ich habe mich in den letzten Jahren viel mit KI beschÃ¤ftigt â€“ von neuronalen Netzen bis zu den neuesten Sprachmodellen.  
Aber was mich am meisten fasziniert, ist der Kern: **Wie lernen Maschinen Ã¼berhaupt?**  
Reinforcement Learning (RL) ist fÃ¼r mich eines der ehrlichsten Paradigmen, weil es so nah an unserem eigenen Lernen dran ist: Versuch und Irrtum, kleine Belohnungen, groÃŸe RÃ¼ckschlÃ¤ge â€“ und langsam entsteht eine Strategie.  

Reward Rover soll genau das zeigen.  
Kein abstraktes Buzzword, sondern eine Erfahrung:  
Du siehst einem Agenten dabei zu, wie er aus â€Fehlernâ€œ etwas Sinnvolles macht.  
Und wenn man versteht, wie dieser Prozess funktioniert, versteht man auch ein StÃ¼ck besser, wie KI-Systeme ihre Welt â€sehenâ€œ und warum sie manchmal Ã¼berraschend gute (oder dumme) Entscheidungen treffen.  

---

## Features

- **Exploration vs. Exploitation**  
  Der zentrale Trade-off im RL: Bleibt der Rover bei sicheren Wegen oder probiert er Neues?  
  Mit jedem Lauf verÃ¤ndert sich sein Verhalten â€“ und du kannst live zuschauen.  

- **Drei Modi**  
  - **Playground:** Baue deine eigene Welt, platziere Mauern, Rewards, Strafen und Portale.  
  - **Zufallsmodus:** Lass dir automatisch generierte Welten erstellen â€“ jedes Mal anders.  
  - **Vergleichsmodus:** Starte zwei Rover gleichzeitig mit unterschiedlichen Hyperparametern (Explorationsrate, Lernrate, Gamma) und sieh, wer schneller lernt.  

- **Q-Learning live erklÃ¤rt**  
  - Q-Werte lassen sich als Zahlen oder Heatmap einblenden.  
  - Du kannst direkt an den Stellschrauben drehen:  
    - **Explorationsrate (Îµ):** Wie neugierig ist der Rover?  
    - **Lernrate (Î±):** Wie stark Ã¼berschreiben neue Erfahrungen alte Werte?  
    - **Discount-Faktor (Î³):** Denkt er kurzfristig oder langfristig?  

- **Levels & Statistik**  
  - Eigene Karten bauen oder Preset-Levels laden.  
  - Nach jeder Episode gibtâ€™s Feedback: Rewards, Strafen, Schritte, Zeit.  
  - Highscores werden gespeichert, damit du Fortschritte vergleichen kannst.  

---

## Wie man spielt

1. Starte das Projekt lokal oder Ã¶ffne die gehostete Version.  
2. WÃ¤hle einen Modus: Playground, Zufall oder Vergleich.  
3. Platziere ein paar Hindernisse oder probier gleich die Preset-Levels.  
4. Klick auf **Start** â€“ und schau, wie der Rover mit jedem Zug schlauer wird.  
5. Passe Parameter an und beobachte, wie sich das Verhalten verÃ¤ndert.  

Es macht einen Unterschied, ob der Rover vorsichtig, gierig oder langfristig denkend unterwegs ist.  
Und genau das ist der Kern von RL: Entscheidungen unter Unsicherheit.  

---

## Warum ist das wichtig?

Wir reden heute viel Ã¼ber â€kÃ¼nstliche Intelligenzâ€œ.  
Doch oft bleibt unklar, wie Maschinen eigentlich lernen, warum sie manchmal erstaunlich gut generalisieren und in anderen Momenten spektakulÃ¤r scheitern.  
RL liefert hier einen SchlÃ¼ssel: Es zeigt, dass Intelligenz nicht aus Zauberei entsteht, sondern aus Feedback, Struktur und unzÃ¤hligen Versuchen.  

Wenn wir das begreifen, kÃ¶nnen wir auch besser einschÃ¤tzen, wo die Grenzen heutiger KI liegen â€“ und wo vielleicht die nÃ¤chsten DurchbrÃ¼che kommen.  
Reward Rover ist fÃ¼r mich ein kleiner Schritt in diese Richtung: ein Tool, das zeigt, wie Lernen funktioniert, und das Diskussionen Ã¼ber KI transparenter macht.  

---

## Tech-Stack

- React + TypeScript  
- Vite  
- Tailwind CSS  
- shadcn/ui  

---

## Installation & Start

Falls du selbst spielen mÃ¶chtest:

```bash
git clone https://github.com/maaxhe/reward-rover-playground.git
cd reward-rover-playground
npm install
npm run dev
