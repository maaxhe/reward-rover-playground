# ğŸš€ Reward Rover  
*(English version below)*

**Reward Rover** ist mein Versuch, Reinforcement Learning greifbar zu machen.  
Nicht in Form von endlosen Formeln oder komplizierten Papers, sondern als interaktives Spiel.  
Ein kleiner Rover lÃ¤uft Ã¼ber ein Grid, stolpert in Mauern, kassiert Strafen oder findet Belohnungen â€“ und lernt dabei mit jeder Episode, bessere Entscheidungen zu treffen.

---

## Warum dieses Projekt?

Ich habe mich in den letzten Jahren viel mit KI beschÃ¤ftigt â€“ von neuronalen Netzen bis zu den neuesten Sprachmodellen.  
Aber was mich am meisten fasziniert, ist der Kern: **Wie lernen Maschinen Ã¼berhaupt?**  
Reinforcement Learning (RL) ist fÃ¼r mich eines der ehrlichsten Paradigmen, weil es so nah an unserem eigenen Lernen dran ist: Versuch und Irrtum, kleine Belohnungen, groÃŸe RÃ¼ckschlÃ¤ge â€“ und langsam entsteht eine Strategie.  

Reward Rover soll genau das zeigen.  
Kein abstraktes Buzzword, sondern eine Erfahrung:  
Du siehst einem Agenten dabei zu, wie er aus â€Fehlernâ€œ etwas Sinnvolles macht.  
Und wenn man versteht, wie dieser Prozess funktioniert, versteht man auch ein StÃ¼ck besser, wie KI-Systeme ihre Welt â€sehenâ€œ und warum sie manchmal Ã¼berraschend gute (oder dumme) Entscheidungen treffen.  

---

## Features

- **Exploration vs. Exploitation**  
  Der zentrale Trade-off im RL: Bleibt der Rover bei sicheren Wegen oder probiert er Neues?  
  Mit jedem Lauf verÃ¤ndert sich sein Verhalten â€“ und du kannst live zuschauen.  

- **Drei Modi**  
  - **Playground:** Baue deine eigene Welt, platziere Mauern, Rewards, Strafen und Portale.  
  - **Zufallsmodus:** Lass dir automatisch generierte Welten erstellen â€“ jedes Mal anders.  
  - **Vergleichsmodus:** Starte zwei Rover gleichzeitig mit unterschiedlichen Hyperparametern (Explorationsrate, Lernrate, Gamma) und sieh, wer schneller lernt.  

- **Q-Learning live erklÃ¤rt**  
  - Q-Werte lassen sich als Zahlen oder Heatmap einblenden.  
  - Du kannst direkt an den Stellschrauben drehen:  
    - **Explorationsrate (Îµ):** Wie neugierig ist der Rover?  
    - **Lernrate (Î±):** Wie stark Ã¼berschreiben neue Erfahrungen alte Werte?  
    - **Discount-Faktor (Î³):** Denkt er kurzfristig oder langfristig?  

- **Levels & Statistik**  
  - Eigene Karten bauen oder Preset-Levels laden.  
  - Nach jeder Episode gibtâ€™s Feedback: Rewards, Strafen, Schritte, Zeit.  
  - Highscores werden gespeichert, damit du Fortschritte vergleichen kannst.  

---

## Wie man spielt

1. Starte das Projekt lokal oder Ã¶ffne die gehostete Version.  
2. WÃ¤hle einen Modus: Playground, Zufall oder Vergleich.  
3. Platziere ein paar Hindernisse oder probier gleich die Preset-Levels.  
4. Klick auf **Start** â€“ und schau, wie der Rover mit jedem Zug schlauer wird.  
5. Passe Parameter an und beobachte, wie sich das Verhalten verÃ¤ndert.  

---

## Warum ist das wichtig?

Wir reden heute viel Ã¼ber â€kÃ¼nstliche Intelligenzâ€œ.  
Doch oft bleibt unklar, wie Maschinen eigentlich lernen, warum sie manchmal erstaunlich gut generalisieren und in anderen Momenten spektakulÃ¤r scheitern.  
RL liefert hier einen SchlÃ¼ssel: Es zeigt, dass Intelligenz nicht aus Zauberei entsteht, sondern aus Feedback, Struktur und unzÃ¤hligen Versuchen.  

Wenn wir das begreifen, kÃ¶nnen wir auch besser einschÃ¤tzen, wo die Grenzen heutiger KI liegen â€“ und wo vielleicht die nÃ¤chsten DurchbrÃ¼che kommen.  
Reward Rover ist fÃ¼r mich ein kleiner Schritt in diese Richtung: ein Tool, das zeigt, wie Lernen funktioniert, und das Diskussionen Ã¼ber KI transparenter macht.  

---

## Tech-Stack

- React + TypeScript  
- Vite  
- Tailwind CSS  
- shadcn/ui  

---

## Installation & Start

Falls du selbst spielen mÃ¶chtest:

```bash
git clone https://github.com/maaxhe/reward-rover-playground.git
cd reward-rover-playground
npm install
npm run dev
```


Danach findest du das Projekt unter http://localhost:5173.

---

## PersÃ¶nliche Note

Dieses Projekt ist nicht â€von Handâ€œ aus dem Nichts entstanden.
Ich habe beim Bauen KI-Tools zur UnterstÃ¼tzung genutzt â€“ fÃ¼r Boilerplate-Code, UI-Ideen und Debugging.
Mir war wichtig, zu zeigen: Man muss heute nicht alles selbst tippen, um spannende Dinge zu erschaffen.
Die Kunst liegt darin, die Werkzeuge klug einzusetzen und daraus etwas Eigenes zu formen.

Reward Rover ist fÃ¼r mich genau das: ein Lernprojekt, das moderne Tools mit meiner eigenen Idee verbindet.
Ich baue es, weil ich glaube, dass wir bessere Debatten Ã¼ber KI fÃ¼hren kÃ¶nnen, wenn wir verstehen, wie sie lernt.
Und weil es einfach SpaÃŸ macht, dem Rover beim Scheitern und besser Werden zuzuschauen.

â€“ Maxim Leopold

---

## Mehr von mir

Du findest den Reward Rover auch direkt auf meiner Website:
ğŸ‘‰ https://www.maximleopold.com

Dort teile ich auÃŸerdem Artikel, Projekte und Gedanken rund um Neuroscience, KI und Gesellschaft.


â¸»

# ğŸš€ Reward Rover (English Version)

Reward Rover is my attempt to make Reinforcement Learning tangible.
Not through endless formulas or dense research papers, but as an interactive game.
A small rover moves across a grid, bumps into walls, collects penalties, finds rewards â€“ and learns to make better decisions with every episode.

---

## Why this project?

Over the past years, Iâ€™ve spent a lot of time working on AI â€“ from neural networks to the latest language models.
But what fascinates me most is the core question: How do machines actually learn?
Reinforcement Learning (RL) feels like one of the most honest paradigms, because itâ€™s so close to the way we humans learn: trial and error, small rewards, big mistakes â€“ and slowly a strategy emerges.

Thatâ€™s what Reward Rover is meant to show.
No abstract buzzword, but an experience:
You can literally watch an agent turn â€œmistakesâ€ into something useful.
And once you understand how this process works, you also understand a bit better how AI systems â€œseeâ€ their world â€“ and why they sometimes make surprisingly good (or dumb) choices.

---

## Features
	â€¢	Exploration vs. Exploitation
The key trade-off in RL: Should the rover stick to safe strategies or try new ones?
With each run, its behavior shifts â€“ and you can watch it live.
	â€¢	Three modes
	â€¢	Playground: Build your own world, place walls, rewards, penalties, and portals.
	â€¢	Random mode: Generate worlds automatically â€“ different each time.
	â€¢	Comparison mode: Run two rovers with different hyperparameters (exploration rate, learning rate, gamma) and see who learns faster.
	â€¢	Q-learning live
	â€¢	Show Q-values as numbers or as a heatmap.
	â€¢	Adjust key parameters:
	â€¢	Exploration rate (Îµ): How curious is the rover?
	â€¢	Learning rate (Î±): How strongly do new experiences overwrite old ones?
	â€¢	Discount factor (Î³): Short-term gains vs. long-term strategy.
	â€¢	Levels & Statistics
	â€¢	Build your own maps or load preset levels.
	â€¢	After each episode: rewards, penalties, steps, time.
	â€¢	Highscores are stored locally so you can track progress.

---

## How to play
	1.	Run the project locally or open the hosted version.
	2.	Choose a mode: Playground, Random, or Comparison.
	3.	Place a few walls or just try the presets.
	4.	Click Start â€“ and watch the rover get smarter with each step.
	5.	Adjust parameters and see how its behavior changes.

---

## Why it matters

We talk a lot about â€œartificial intelligenceâ€ these days.
But itâ€™s often unclear how machines really learn, why they sometimes generalize astonishingly well, and why they fail so spectacularly in other cases.
RL provides a key: it shows that intelligence doesnâ€™t come from magic, but from feedback, structure, and countless trials.

Understanding this helps us see where todayâ€™s AI has limits â€“ and where breakthroughs might come next.
For me, Reward Rover is a small step in that direction: a tool to show how learning works, and to make conversations about AI more transparent.

---

## Tech Stack
	â€¢	React + TypeScript
	â€¢	Vite
	â€¢	Tailwind CSS
	â€¢	shadcn/ui

---

## Installation & Run

If you want to try it yourself:

```bash
git clone https://github.com/maaxhe/reward-rover-playground.git
cd reward-rover-playground
npm install
npm run dev
```

Then open http://localhost:5173.

---

## Personal note

This project wasnâ€™t created â€œby handâ€ from scratch.
I built it with the help of AI tools â€“ for boilerplate code, UI ideas, and debugging.
For me, the important part was to show that you donâ€™t have to type every single line yourself to build something meaningful.
The art lies in using the tools wisely and shaping something of your own.

Reward Rover is exactly that for me: a learning project that combines modern tools with my own ideas.
I built it because I believe we can have better debates about AI once we actually understand how it learns.
And also because itâ€™s just fun to watch the rover fail and improve.

â€“ Maxim Leopold

---

## More from me

You can also try the Reward Rover directly on my website:
ğŸ‘‰ https://www.maximleopold.com

There I share articles, projects, and thoughts on neuroscience, AI, and society.
