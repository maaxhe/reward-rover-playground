# Reinforcement Learning Modules

This directory contains refactored, tested, and maintainable RL modules extracted from the original monolithic `RLGame.tsx` component.

## ğŸ“ Structure

```
src/lib/rl/
â”œâ”€â”€ index.ts              # Main export file
â”œâ”€â”€ types.ts              # Type definitions
â”œâ”€â”€ constants.ts          # RL constants and configurations
â”œâ”€â”€ gridUtils.ts          # Grid operations and utilities
â”œâ”€â”€ qLearning.ts          # Q-Learning algorithm implementation
â”œâ”€â”€ portalUtils.ts        # Portal teleportation logic
â”œâ”€â”€ gridUtils.test.ts     # Grid utilities tests (27 tests)
â”œâ”€â”€ qLearning.test.ts     # Q-Learning tests (26 tests)
â””â”€â”€ portalUtils.test.ts   # Portal utilities tests (24 tests)
```

## âœ… Test Coverage

All modules are fully unit tested with **77 passing tests**:

- **Grid Utils**: 27 tests covering grid creation, manipulation, and statistics
- **Q-Learning**: 26 tests covering action selection, Q-value updates, and rewards
- **Portal Utils**: 24 tests covering portal teleportation and cooldown management

Run tests with:
```bash
npm test
```

## ğŸ¯ Modules Overview

### `types.ts`
Core type definitions for the RL system:
- `Position`, `TileState`, `EpisodeStats`
- State interfaces: `PlaygroundState`, `RandomModeState`, `ComparisonState`
- Configuration types: `LevelConfig`, `PresetLevel`

### `constants.ts`
RL hyperparameters and game configuration:
- **Hyperparameters**: `LEARNING_RATE`, `DISCOUNT_FACTOR`, exploration settings
- **Rewards**: `REWARD_VALUE`, `PUNISHMENT_VALUE`, `GOAL_REWARD`
- **Level Configs**: Preset levels, speedrun stages, episode titles
- **UI Labels**: Multilingual labels for DE/EN

### `gridUtils.ts`
Grid manipulation and utilities:
- `createEmptyGrid()` - Create empty grid
- `cloneGrid()` - Deep clone grid state
- `manhattanDistance()` - Calculate distance between positions
- `selectGoalPositions()` - Smart goal placement
- `generateMaze()` - Maze generation using recursive backtracking
- `computeMoveStats()` / `computeEpisodeSummary()` - Statistics calculation

### `qLearning.ts`
Q-Learning algorithm implementation:
- `getPossibleActions()` - Get valid moves from position
- `chooseAction()` - Epsilon-greedy action selection
- `getBestActionDirection()` - Get best action for visualization
- `getTileReward()` - Calculate reward for tile type
- `updateQValue()` - Q-learning update rule: Q(s,a) â† Q(s,a) + Î±[r + Î³ max Q(s',a') - Q(s,a)]
- `getMaxQValue()` - Get maximum Q-value from possible actions

### `portalUtils.ts`
Portal teleportation system:
- `findPortals()` - Find all portal positions
- `teleportThroughPortal()` - Random portal teleportation
- `decrementPortalCooldowns()` - Cooldown management
- `isPortalOnCooldown()` - Check if portal is usable

## ğŸš€ Usage

Import from the main index:

```typescript
import {
  // Types
  Position,
  TileState,
  EpisodeStats,

  // Constants
  LEARNING_RATE,
  DISCOUNT_FACTOR,
  REWARD_VALUE,

  // Grid Utils
  createEmptyGrid,
  manhattanDistance,
  selectGoalPositions,

  // Q-Learning
  getPossibleActions,
  chooseAction,
  updateQValue,

  // Portal Utils
  findPortals,
  teleportThroughPortal,
} from '@/lib/rl';
```

## ğŸ“ Q-Learning Implementation

This implementation uses the classic Q-Learning algorithm:

```
Q(s,a) â† Q(s,a) + Î±[r + Î³ max Q(s',a') - Q(s,a)]
```

Where:
- `Î±` (alpha) = Learning rate (default: 0.1)
- `Î³` (gamma) = Discount factor (default: 0.85)
- `r` = Immediate reward
- `Q(s,a)` = Q-value for state-action pair
- `max Q(s',a')` = Maximum Q-value of next state

### Action Selection

Uses epsilon-greedy policy:
- With probability `Îµ`: explore (random action)
- With probability `1-Îµ`: exploit (best Q-value action)

## ğŸ“Š Benefits of Refactoring

âœ… **Testability**: 77 unit tests ensure correctness
âœ… **Maintainability**: Clear separation of concerns
âœ… **Reusability**: Functions can be used independently
âœ… **Documentation**: Each function is well-documented
âœ… **Type Safety**: Full TypeScript typing
âœ… **Debuggability**: Easier to debug isolated functions

## ğŸ”„ Migration Guide

The original `RLGame.tsx` still contains all logic for backward compatibility. To migrate:

1. Import needed functions from `@/lib/rl`
2. Replace inline implementations with imported functions
3. Test thoroughly
4. Remove duplicated code from `RLGame.tsx`

## ğŸ§ª Running Tests

```bash
# Run all tests
npm test

# Run tests in watch mode
npm test -- --watch

# Run tests with UI
npm run test:ui

# Run tests with coverage
npm run test:coverage
```

## ğŸ“ˆ Future Improvements

- [ ] Extract game loop logic into `useGameLoop` hook
- [ ] Extract state management into context providers
- [ ] Add more RL algorithms (SARSA, DQN)
- [ ] Add performance benchmarks
- [ ] Add integration tests

## ğŸ¤ Contributing

When adding new RL features:
1. Add implementation to appropriate module
2. Write comprehensive tests
3. Update this README
4. Ensure all tests pass

---

**Created**: 2025-01-18
**Test Status**: âœ… 77/77 passing
**Coverage**: Grid Utils, Q-Learning, Portal Utils
